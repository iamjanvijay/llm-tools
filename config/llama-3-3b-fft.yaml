# ------------------------ model & tokenizer --------------------------
base_model: meta-llama/Llama-3.2-3B-Instruct
model_type: AutoModelForCausalLM
tokenizer_type: AutoTokenizer
trust_remote_code: true
load_in_8bit: false
load_in_4bit: false
strict: false
special_tokens:
  pad_token: "<|end_of_text|>"   # this is the first EOS token in Llama-3.*

# --------------------------- dataset ---------------------------------
seed: 42
dataset_processes: 64

datasets:
  - path: /jvsingh2/dummy_train/dataset/judge_data.jsonl
    type: chat_template
    chat_template: tokenizer_default
    field_messages: conversations
    message_property_mappings:
      role: from
      content: value
    roles:
      user: ["user"]
      assistant: ["assistant"]
    roles_to_train: ["assistant"]
    train_on_eos: turn
    message_field_training: train
    shuffle: true

val_set_size: 0 
dataset_prepared_path: /jvsingh2/dummy_train/train_cache/dataset
output_dir: /jvsingh2/dummy_train/train_cache/ckpts

# ------------------------ sequence & packing -------------------------
sequence_len: 6500
sample_packing: false
eval_sample_packing: false
pad_to_sequence_len: true

# ------------------------- logging / tracking ------------------------
wandb_project: offline-cot-pruning
wandb_entity: ksartik-georgia-institute-of-technology
wandb_name: dummy_train
use_tensorboard: false
wandb_watch:
wandb_log_model:

# ------------------------ training hyper-params ----------------------
gradient_accumulation_steps: 1
micro_batch_size: 4
num_epochs: 1
optimizer: adamw_torch_fused
learning_rate: 1e-5
lr_scheduler: cosine
bf16: true
fp16: false
tf32: false
gradient_checkpointing: true
flash_attention: true
resume_from_checkpoint:

# -------------------- evaluation & checkpointing --------------------
warmup_steps: 
# eval_steps: 100
# evaluation_strategy: steps
save_steps: 50
save_strategy: steps
save_total_limit: 30
load_best_model_at_end: false

# ---------------------------- misc / system -------------------------
weight_decay: 0.0
deepspeed: /jvsingh2/dummy_train/config/zero3.json
